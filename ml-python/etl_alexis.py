import pandas as pd
import re
import os

def clean_text_expert(text):
    if not isinstance(text, str): return ""
    # 1. NormalizaciÃ³n bÃ¡sica
    text = text.lower()
    # 2. Limpieza de caracteres (mantenemos Ã± y tildes para el contexto espaÃ±ol)
    text = re.sub(r'[^a-zÃ±Ã¡Ã©Ã­Ã³Ãº\s]', '', text)
    # 3. Eliminar espacios extra
    text = re.sub(r'\s+', ' ', text).strip()
    return text

print("ðŸš€ Iniciando ETL de nivel experto...")

# Carga del dataset original
df = pd.read_csv('data/raw/Big_AHR.csv')

# --- TRATAMIENTO DE NULOS ---
# Eliminamos cualquier fila que no tenga texto o etiqueta (son inservibles para ML)
antes_nulos = len(df)
df = df.dropna(subset=['review_text', 'label'])
print(f"ðŸ—‘ï¸ Nulos eliminados: {antes_nulos - len(df)}")

# --- TRATAMIENTO DE DUPLICADOS ---
# A veces la misma reseÃ±a aparece varias veces con la misma o diferente etiqueta
antes_duplicados = len(df)
df = df.drop_duplicates(subset=['review_text'], keep='first')
print(f"ðŸ—‘ï¸ Duplicados eliminados: {antes_duplicados - len(df)}")

# --- LIMPIEZA DE ETIQUETAS (LABEL) ---
# Nos aseguramos de que solo queden las etiquetas del contrato: 0, 1 y 3
# Si hay algÃºn valor extraÃ±o, lo eliminamos
df = df[df['label'].isin([0, 1, 3])]
df['label'] = df['label'].astype(int)

# --- NORMALIZACIÃ“N DE TEXTO ---
print("ðŸ§¹ Normalizando texto (esto toma un momento)...")
df['clean_text'] = df['review_text'].apply(clean_text_expert)

# --- FILTRO POST-LIMPIEZA ---
# Si despuÃ©s de limpiar el texto quedÃ³ vacÃ­o (solo eran emojis o sÃ­mbolos), lo borramos
df = df[df['clean_text'].str.len() > 2]

# --- GUARDADO ---
os.makedirs('data/processed', exist_ok=True)
ruta_final = 'data/processed/dataset_master.csv'
df.to_csv(ruta_final, index=False)

print("-" * 30)
print(f"âœ… ETL FINALIZADO CON Ã‰XITO")
print(f"ðŸ“Š Registros finales: {len(df)}")
print(f"ðŸ“‚ Archivo maestro creado en: {ruta_final}")
print("-" * 30)